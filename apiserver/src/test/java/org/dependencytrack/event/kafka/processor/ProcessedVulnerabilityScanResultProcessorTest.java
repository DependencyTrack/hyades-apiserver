/*
 * This file is part of Dependency-Track.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-License-Identifier: Apache-2.0
 * Copyright (c) OWASP Foundation. All Rights Reserved.
 */
package org.dependencytrack.event.kafka.processor;

import alpine.event.framework.Event;
import alpine.event.framework.EventService;
import alpine.event.framework.Subscriber;
import org.dependencytrack.event.ComponentMetricsUpdateEvent;
import org.dependencytrack.event.ComponentPolicyEvaluationEvent;
import org.dependencytrack.event.ProjectMetricsUpdateEvent;
import org.dependencytrack.event.ProjectPolicyEvaluationEvent;
import org.dependencytrack.event.kafka.KafkaTopics;
import org.dependencytrack.model.Component;
import org.dependencytrack.model.Project;
import org.dependencytrack.model.VulnerabilityScan;
import org.dependencytrack.model.WorkflowState;
import org.dependencytrack.model.WorkflowStatus;
import org.dependencytrack.model.WorkflowStep;
import org.dependencytrack.persistence.jdbi.WorkflowDao;
import org.dependencytrack.proto.notification.v1.BomConsumedOrProcessedSubject;
import org.dependencytrack.proto.notification.v1.Notification;
import org.dependencytrack.proto.notification.v1.ProjectVulnAnalysisCompleteSubject;
import org.dependencytrack.proto.vulnanalysis.v1.ScanResult;
import org.dependencytrack.proto.vulnanalysis.v1.ScannerResult;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.ConcurrentLinkedQueue;

import static org.assertj.core.api.Assertions.assertThat;
import static org.awaitility.Awaitility.await;
import static org.dependencytrack.persistence.jdbi.JdbiFactory.withJdbiHandle;
import static org.dependencytrack.proto.notification.v1.Group.GROUP_BOM_PROCESSED;
import static org.dependencytrack.proto.notification.v1.Group.GROUP_PROJECT_VULN_ANALYSIS_COMPLETE;
import static org.dependencytrack.proto.notification.v1.Level.LEVEL_INFORMATIONAL;
import static org.dependencytrack.proto.notification.v1.ProjectVulnAnalysisStatus.PROJECT_VULN_ANALYSIS_STATUS_COMPLETED;
import static org.dependencytrack.proto.notification.v1.ProjectVulnAnalysisStatus.PROJECT_VULN_ANALYSIS_STATUS_FAILED;
import static org.dependencytrack.proto.notification.v1.Scope.SCOPE_PORTFOLIO;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_FAILED;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_SUCCESSFUL;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_INTERNAL;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_OSSINDEX;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_SNYK;
import static org.dependencytrack.util.KafkaTestUtil.deserializeKey;
import static org.dependencytrack.util.KafkaTestUtil.deserializeValue;

public class ProcessedVulnerabilityScanResultProcessorTest extends AbstractProcessorTest {

    @Before
    @Override
    public void before() throws Exception {
        super.before();

        EventService.getInstance().subscribe(ComponentMetricsUpdateEvent.class, EventSubscriber.class);
        EventService.getInstance().subscribe(ProjectMetricsUpdateEvent.class, EventSubscriber.class);
        EventService.getInstance().subscribe(ComponentPolicyEvaluationEvent.class, EventSubscriber.class);
        EventService.getInstance().subscribe(ProjectPolicyEvaluationEvent.class, EventSubscriber.class);
    }

    @After
    @Override
    public void after() {
        EventService.getInstance().unsubscribe(EventSubscriber.class);
        EVENTS.clear();

        super.after();
    }

    @Test
    public void testProcessWithFailureThresholdExceeded() throws Exception {
        final var project = new Project();
        project.setName("acme-app");
        qm.persist(project);

        final UUID workflowToken = UUID.randomUUID();
        qm.createWorkflowSteps(workflowToken);

        // Create a VulnerabilityScan, and configure it such that no more than 30%
        // of scanners are allowed to fail in order for the scan to be considered successful.
        final var vulnScan = new VulnerabilityScan();
        vulnScan.setToken(workflowToken);
        vulnScan.setTargetType(VulnerabilityScan.TargetType.PROJECT);
        vulnScan.setTargetIdentifier(project.getUuid());
        vulnScan.setStatus(VulnerabilityScan.Status.IN_PROGRESS);
        vulnScan.setExpectedResults(3);
        vulnScan.setFailureThreshold(0.3);
        vulnScan.setStartedAt(new Date());
        vulnScan.setUpdatedAt(vulnScan.getStartedAt());
        qm.persist(vulnScan);

        // Create 3 ScanResults, each with 2 successful and 1 failed ScannerResult.
        final var scanResults = new ArrayList<ScanResult>();
        for (int i = 0; i < 3; i++) {
            scanResults.add(ScanResult.newBuilder()
                    .addScannerResults(ScannerResult.newBuilder()
                            .setScanner(SCANNER_INTERNAL)
                            .setStatus(SCAN_STATUS_SUCCESSFUL))
                    .addScannerResults(ScannerResult.newBuilder()
                            .setScanner(SCANNER_OSSINDEX)
                            .setStatus(SCAN_STATUS_SUCCESSFUL))
                    .addScannerResults(ScannerResult.newBuilder()
                            .setScanner(SCANNER_SNYK)
                            .setStatus(SCAN_STATUS_FAILED))
                    .build());
        }

        final var processor = new ProcessedVulnerabilityScanResultProcessor();
        processor.process(scanResults.stream().map(result -> aConsumerRecord(vulnScan.getToken().toString(), result).build()).toList());

        qm.getPersistenceManager().refresh(vulnScan);
        assertThat(vulnScan.getStatus()).isEqualTo(VulnerabilityScan.Status.FAILED);
        qm.getPersistenceManager().refreshAll(qm.getAllWorkflowStatesForAToken(workflowToken));
        assertThat(qm.getAllWorkflowStatesForAToken(workflowToken)).satisfiesExactlyInAnyOrder(
                workflowState -> assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.BOM_CONSUMPTION),
                workflowState -> assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.BOM_PROCESSING),
                workflowState -> {
                    assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.VULN_ANALYSIS);
                    assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.FAILED);
                    assertThat(workflowState.getFailureReason()).isEqualTo("Failure threshold of 30.00% exceeded: 3/9 of scans failed");
                },
                workflowState -> {
                    assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.POLICY_EVALUATION);
                    assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.CANCELLED);
                    assertThat(workflowState.getFailureReason()).isNull();
                },
                workflowState -> {
                    assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.METRICS_UPDATE);
                    assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.CANCELLED);
                    assertThat(workflowState.getFailureReason()).isNull();
                }
        );

        assertThat(kafkaMockProducer.history()).satisfiesExactly(record -> {
            assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE.name());

            final String recordKey = deserializeKey(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE, record);
            assertThat(recordKey).isEqualTo(project.getUuid().toString());

            final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE, record);
            assertThat(notification.getScope()).isEqualTo(SCOPE_PORTFOLIO);
            assertThat(notification.getGroup()).isEqualTo(GROUP_PROJECT_VULN_ANALYSIS_COMPLETE);
            assertThat(notification.getLevel()).isEqualTo(LEVEL_INFORMATIONAL);
            assertThat(notification.getSubject().is(ProjectVulnAnalysisCompleteSubject.class)).isTrue();

            final var subject = notification.getSubject().unpack(ProjectVulnAnalysisCompleteSubject.class);
            assertThat(subject.getToken()).isEqualTo(workflowToken.toString());
            assertThat(subject.getStatus()).isEqualTo(PROJECT_VULN_ANALYSIS_STATUS_FAILED);
            assertThat(subject.getProject().getUuid()).isEqualTo(project.getUuid().toString());
            assertThat(subject.getFindingsCount()).isZero();
        });

        assertThat(EVENTS).isEmpty();
    }

    @Test
    public void testProcessWithResultWithoutScannerResults() throws Exception {
        final var project = new Project();
        project.setName("acme-app");
        qm.persist(project);

        final UUID workflowToken = UUID.randomUUID();
        qm.createWorkflowSteps(workflowToken);

        final var vulnScan = new VulnerabilityScan();
        vulnScan.setToken(workflowToken);
        vulnScan.setTargetType(VulnerabilityScan.TargetType.PROJECT);
        vulnScan.setTargetIdentifier(project.getUuid());
        vulnScan.setStatus(VulnerabilityScan.Status.IN_PROGRESS);
        vulnScan.setExpectedResults(1);
        vulnScan.setStartedAt(new Date());
        vulnScan.setUpdatedAt(vulnScan.getStartedAt());
        qm.persist(vulnScan);

        // Create a ScanResult without any ScannerResults attached to it.
        // This might happen when no scanner is capable of scanning a component,
        // or when all scanners are disabled.
        final var scanResult = ScanResult.newBuilder().build();

        final var processor = new ProcessedVulnerabilityScanResultProcessor();
        processor.process(List.of(aConsumerRecord(vulnScan.getToken().toString(), scanResult).build()));

        qm.getPersistenceManager().refresh(vulnScan);
        assertThat(vulnScan.getStatus()).isEqualTo(VulnerabilityScan.Status.COMPLETED);
        qm.getPersistenceManager().refreshAll(qm.getAllWorkflowStatesForAToken(workflowToken));
        assertThat(qm.getAllWorkflowStatesForAToken(workflowToken)).satisfiesExactlyInAnyOrder(
                workflowState -> assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.BOM_CONSUMPTION),
                workflowState -> assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.BOM_PROCESSING),
                workflowState -> {
                    assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.VULN_ANALYSIS);
                    assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.COMPLETED);
                    assertThat(workflowState.getFailureReason()).isNull();
                },
                workflowState -> {
                    assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.POLICY_EVALUATION);
                    assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.PENDING);
                    assertThat(workflowState.getFailureReason()).isNull();
                },
                workflowState -> {
                    assertThat(workflowState.getStep()).isEqualTo(WorkflowStep.METRICS_UPDATE);
                    assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.PENDING);
                    assertThat(workflowState.getFailureReason()).isNull();
                }
        );

        assertThat(kafkaMockProducer.history()).satisfiesExactly(record -> {
            assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE.name());

            final String recordKey = deserializeKey(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE, record);
            assertThat(recordKey).isEqualTo(project.getUuid().toString());

            final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE, record);
            assertThat(notification.getScope()).isEqualTo(SCOPE_PORTFOLIO);
            assertThat(notification.getGroup()).isEqualTo(GROUP_PROJECT_VULN_ANALYSIS_COMPLETE);
            assertThat(notification.getLevel()).isEqualTo(LEVEL_INFORMATIONAL);
            assertThat(notification.getSubject().is(ProjectVulnAnalysisCompleteSubject.class)).isTrue();

            final var subject = notification.getSubject().unpack(ProjectVulnAnalysisCompleteSubject.class);
            assertThat(subject.getStatus()).isEqualTo(PROJECT_VULN_ANALYSIS_STATUS_COMPLETED);
            assertThat(subject.getProject().getUuid()).isEqualTo(project.getUuid().toString());
            assertThat(subject.getFindingsCount()).isZero();
        });

        await("Internal event publish")
                .atMost(Duration.ofSeconds(1))
                .untilAsserted(() -> assertThat(EVENTS).satisfiesExactly(
                        event -> {
                            assertThat(event).isInstanceOf(ProjectPolicyEvaluationEvent.class);
                            final var policyEvalEvent = (ProjectPolicyEvaluationEvent) event;
                            assertThat(policyEvalEvent.getUuid()).isEqualTo(project.getUuid());
                            assertThat(policyEvalEvent.getChainIdentifier()).isEqualTo(workflowToken);
                        },
                        event -> {
                            assertThat(event).isInstanceOf(ProjectMetricsUpdateEvent.class);
                            final var metricsUpdateEvent = (ProjectMetricsUpdateEvent) event;
                            assertThat(metricsUpdateEvent.getUuid()).isEqualTo(project.getUuid());
                            assertThat(metricsUpdateEvent.getChainIdentifier()).isEqualTo(workflowToken);
                        }
                ));
    }

    @Test
    public void testProcessWithDelayedBomProcessedNotification() throws Exception {
        final var project = new Project();
        project.setName("acme-app");
        qm.persist(project);

        final UUID workflowToken = UUID.randomUUID();
        qm.createWorkflowSteps(workflowToken);

        // Transition BOM_PROCESSING step to COMPLETED status,
        // without this we won't send a BOM_PROCESSED notification.
        withJdbiHandle(handle -> handle.attach(WorkflowDao.class)
                .updateState(WorkflowStep.BOM_PROCESSING, workflowToken, WorkflowStatus.COMPLETED, /* failureReason */ null));

        // Create a VulnerabilityScan, and configure it such that no more than 10%
        // of scanners are allowed to fail in order for the scan to be considered successful.
        final var vulnScan = new VulnerabilityScan();
        vulnScan.setToken(workflowToken);
        vulnScan.setTargetType(VulnerabilityScan.TargetType.PROJECT);
        vulnScan.setTargetIdentifier(project.getUuid());
        vulnScan.setStatus(VulnerabilityScan.Status.IN_PROGRESS);
        vulnScan.setExpectedResults(1);
        vulnScan.setStartedAt(new Date());
        vulnScan.setUpdatedAt(vulnScan.getStartedAt());
        qm.persist(vulnScan);

        // Create a ScanResult without any ScannerResults attached to it.
        // This might happen when no scanner is capable of scanning a component,
        // or when all scanners are disabled.
        final var scanResult = ScanResult.newBuilder().build();

        final var processor = new ProcessedVulnerabilityScanResultProcessor(/* shouldDispatchBomProcessedNotification */ true);
        processor.process(List.of(aConsumerRecord(vulnScan.getToken().toString(), scanResult).build()));

        assertThat(kafkaMockProducer.history()).satisfiesExactly(
                record -> assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE.name()),
                record -> {
                    assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_BOM.name());

                    final String recordKey = deserializeKey(KafkaTopics.NOTIFICATION_BOM, record);
                    assertThat(recordKey).isEqualTo(project.getUuid().toString());

                    final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_BOM, record);
                    assertThat(notification.getScope()).isEqualTo(SCOPE_PORTFOLIO);
                    assertThat(notification.getGroup()).isEqualTo(GROUP_BOM_PROCESSED);
                    assertThat(notification.getLevel()).isEqualTo(LEVEL_INFORMATIONAL);
                    assertThat(notification.getSubject().is(BomConsumedOrProcessedSubject.class)).isTrue();

                    final var subject = notification.getSubject().unpack(BomConsumedOrProcessedSubject.class);
                    assertThat(subject.getToken()).isEqualTo(workflowToken.toString());
                    assertThat(subject.getProject().getUuid()).isEqualTo(project.getUuid().toString());
                }
        );

        await("Internal event publish")
                .atMost(Duration.ofSeconds(1))
                .untilAsserted(() -> assertThat(EVENTS).satisfiesExactly(
                        event -> assertThat(event).isInstanceOf(ProjectPolicyEvaluationEvent.class),
                        event -> assertThat(event).isInstanceOf(ProjectMetricsUpdateEvent.class)
                ));
    }

    @Test
    public void testProcessWithDelayedBomProcessedNotificationWhenVulnerabilityScanFailed() throws Exception {
        final var project = new Project();
        project.setName("acme-app");
        qm.persist(project);

        final UUID workflowToken = UUID.randomUUID();
        qm.createWorkflowSteps(workflowToken);

        // Transition BOM_PROCESSING step to COMPLETED status,
        // without this we won't send a BOM_PROCESSED notification.
        withJdbiHandle(handle -> handle.attach(WorkflowDao.class)
                .updateState(WorkflowStep.BOM_PROCESSING, workflowToken, WorkflowStatus.COMPLETED, /* failureReason */ null));

        final var vulnScan = new VulnerabilityScan();
        vulnScan.setToken(workflowToken);
        vulnScan.setTargetType(VulnerabilityScan.TargetType.PROJECT);
        vulnScan.setTargetIdentifier(project.getUuid());
        vulnScan.setStatus(VulnerabilityScan.Status.IN_PROGRESS);
        vulnScan.setExpectedResults(1);
        vulnScan.setFailureThreshold(0.1);
        vulnScan.setStartedAt(new Date());
        vulnScan.setUpdatedAt(vulnScan.getStartedAt());
        qm.persist(vulnScan);

        // Create a ScanResult, with only one failed ScannerResult (i.e. 100% failure rate).
        final var scanResult = ScanResult.newBuilder()
                .addScannerResults(ScannerResult.newBuilder()
                        .setScanner(SCANNER_INTERNAL)
                        .setStatus(SCAN_STATUS_FAILED))
                .build();

        final var processor = new ProcessedVulnerabilityScanResultProcessor(/* shouldDispatchBomProcessedNotification */ true);
        processor.process(List.of(aConsumerRecord(vulnScan.getToken().toString(), scanResult).build()));

        assertThat(kafkaMockProducer.history()).satisfiesExactly(
                record -> assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE.name()),
                record -> {
                    assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_BOM.name());

                    final String recordKey = deserializeKey(KafkaTopics.NOTIFICATION_BOM, record);
                    assertThat(recordKey).isEqualTo(project.getUuid().toString());

                    final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_BOM, record);
                    assertThat(notification.getScope()).isEqualTo(SCOPE_PORTFOLIO);
                    assertThat(notification.getGroup()).isEqualTo(GROUP_BOM_PROCESSED);
                    assertThat(notification.getLevel()).isEqualTo(LEVEL_INFORMATIONAL);
                    assertThat(notification.getSubject().is(BomConsumedOrProcessedSubject.class)).isTrue();

                    final var subject = notification.getSubject().unpack(BomConsumedOrProcessedSubject.class);
                    assertThat(subject.getToken()).isEqualTo(workflowToken.toString());
                    assertThat(subject.getProject().getUuid()).isEqualTo(project.getUuid().toString());
                }
        );

        assertThat(EVENTS).isEmpty();
    }

    @Test
    public void testProcessWithDelayedBomProcessedNotificationWithoutCompletedBomProcessingWorkflowStep() throws Exception {
        final var project = new Project();
        project.setName("acme-app");
        qm.persist(project);

        final UUID workflowToken = UUID.randomUUID();
        qm.createWorkflowSteps(workflowToken);

        // NB: BOM_PROCESSING workflow step remains in status PENDING

        // Create a VulnerabilityScan, and configure it such that no more than 10%
        // of scanners are allowed to fail in order for the scan to be considered successful.
        final var vulnScan = new VulnerabilityScan();
        vulnScan.setToken(workflowToken);
        vulnScan.setTargetType(VulnerabilityScan.TargetType.PROJECT);
        vulnScan.setTargetIdentifier(project.getUuid());
        vulnScan.setStatus(VulnerabilityScan.Status.IN_PROGRESS);
        vulnScan.setExpectedResults(1);
        vulnScan.setStartedAt(new Date());
        vulnScan.setUpdatedAt(vulnScan.getStartedAt());
        qm.persist(vulnScan);

        // Create a ScanResult without any ScannerResults attached to it.
        // This might happen when no scanner is capable of scanning a component,
        // or when all scanners are disabled.
        final var scanResult = ScanResult.newBuilder().build();

        final var processor = new ProcessedVulnerabilityScanResultProcessor(/* shouldDispatchBomProcessedNotification */ true);
        processor.process(List.of(aConsumerRecord(vulnScan.getToken().toString(), scanResult).build()));

        assertThat(kafkaMockProducer.history()).satisfiesExactly(record ->
                assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_PROJECT_VULN_ANALYSIS_COMPLETE.name()));

        await("Internal event publish")
                .atMost(Duration.ofSeconds(1))
                .untilAsserted(() -> assertThat(EVENTS).satisfiesExactly(
                        event -> assertThat(event).isInstanceOf(ProjectPolicyEvaluationEvent.class),
                        event -> assertThat(event).isInstanceOf(ProjectMetricsUpdateEvent.class)
                ));
    }

    @Test
    public void testProcessWithDelayedBomProcessedNotificationWhenVulnerabilityScanTargetIsComponent() throws Exception {
        final var project = new Project();
        project.setName("acme-app");
        qm.persist(project);

        final var component = new Component();
        component.setProject(project);
        component.setName("acme-lib");
        component.setVersion("1.0.0");
        qm.persist(component);

        final UUID workflowToken = UUID.randomUUID();
        final var workflowState = new WorkflowState();
        workflowState.setToken(workflowToken);
        workflowState.setStep(WorkflowStep.VULN_ANALYSIS);
        workflowState.setStatus(WorkflowStatus.PENDING);
        workflowState.setStartedAt(new Date());
        workflowState.setUpdatedAt(workflowState.getStartedAt());
        qm.persist(workflowState);

        final var vulnScan = new VulnerabilityScan();
        vulnScan.setToken(workflowToken);
        vulnScan.setTargetType(VulnerabilityScan.TargetType.COMPONENT);
        vulnScan.setTargetIdentifier(component.getUuid());
        vulnScan.setStatus(VulnerabilityScan.Status.IN_PROGRESS);
        vulnScan.setExpectedResults(1);
        vulnScan.setFailureThreshold(0.1);
        vulnScan.setStartedAt(new Date());
        vulnScan.setUpdatedAt(vulnScan.getStartedAt());
        qm.persist(vulnScan);

        final var scanResult = ScanResult.newBuilder()
                .addScannerResults(ScannerResult.newBuilder()
                        .setScanner(SCANNER_INTERNAL)
                        .setStatus(SCAN_STATUS_SUCCESSFUL))
                .build();

        final var processor = new ProcessedVulnerabilityScanResultProcessor(/* shouldDispatchBomProcessedNotification */ true);
        processor.process(List.of(aConsumerRecord(vulnScan.getToken().toString(), scanResult).build()));

        qm.getPersistenceManager().refreshAll(vulnScan, workflowState);
        assertThat(vulnScan.getStatus()).isEqualTo(VulnerabilityScan.Status.COMPLETED);
        assertThat(workflowState.getStatus()).isEqualTo(WorkflowStatus.COMPLETED);

        assertThat(kafkaMockProducer.history()).isEmpty();

        await("Internal event publish")
                .atMost(Duration.ofSeconds(1))
                .untilAsserted(() -> assertThat(EVENTS).satisfiesExactly(
                        event -> {
                            assertThat(event).isInstanceOf(ComponentPolicyEvaluationEvent.class);
                            final var policyEvalEvent = (ComponentPolicyEvaluationEvent) event;
                            assertThat(policyEvalEvent.getUuid()).isEqualTo(component.getUuid());
                            assertThat(policyEvalEvent.getChainIdentifier()).isEqualTo(workflowToken);
                        },
                        event -> {
                            assertThat(event).isInstanceOf(ComponentMetricsUpdateEvent.class);
                            final var metricsUpdateEvent = (ComponentMetricsUpdateEvent) event;
                            assertThat(metricsUpdateEvent.getUuid()).isEqualTo(component.getUuid());
                            assertThat(metricsUpdateEvent.getChainIdentifier()).isEqualTo(workflowToken);
                        }
                ));
    }

    private static final ConcurrentLinkedQueue<Event> EVENTS = new ConcurrentLinkedQueue<>();

    public static class EventSubscriber implements Subscriber {

        @Override
        public void inform(final Event event) {
            EVENTS.add(event);
        }

    }

}