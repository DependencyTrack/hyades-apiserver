package org.dependencytrack.event.kafka.processor;

import org.apache.kafka.common.header.Headers;
import org.apache.kafka.common.header.internals.RecordHeaders;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.serialization.UUIDDeserializer;
import org.apache.kafka.common.serialization.UUIDSerializer;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.TestInputTopic;
import org.apache.kafka.streams.TestOutputTopic;
import org.apache.kafka.streams.TopologyTestDriver;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.test.TestRecord;
import org.dependencytrack.PersistenceCapableTest;
import org.dependencytrack.event.kafka.KafkaEventHeaders;
import org.dependencytrack.event.kafka.KafkaTopics;
import org.dependencytrack.event.kafka.serialization.KafkaProtobufDeserializer;
import org.dependencytrack.event.kafka.serialization.KafkaProtobufSerde;
import org.dependencytrack.event.kafka.serialization.KafkaProtobufSerializer;
import org.dependencytrack.model.AnalyzerIdentity;
import org.dependencytrack.model.Component;
import org.dependencytrack.model.Finding;
import org.dependencytrack.model.FindingAttribution;
import org.dependencytrack.model.Project;
import org.dependencytrack.model.Vulnerability;
import org.dependencytrack.model.VulnerabilityAnalysisLevel;
import org.dependencytrack.notification.NotificationConstants;
import org.hyades.proto.notification.v1.NewVulnerabilitySubject;
import org.hyades.proto.notification.v1.Notification;
import org.hyades.proto.vulnanalysis.v1.ScanKey;
import org.hyades.proto.vulnanalysis.v1.ScanResult;
import org.hyades.proto.vulnanalysis.v1.ScanStatus;
import org.hyades.proto.vulnanalysis.v1.Scanner;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import java.util.List;
import java.util.UUID;

import static org.assertj.core.api.Assertions.assertThat;
import static org.dependencytrack.util.KafkaTestUtil.deserializeValue;
import static org.hyades.proto.notification.v1.Group.GROUP_ANALYZER;
import static org.hyades.proto.notification.v1.Group.GROUP_NEW_VULNERABILITY;
import static org.hyades.proto.notification.v1.Level.LEVEL_ERROR;
import static org.hyades.proto.notification.v1.Level.LEVEL_INFORMATIONAL;
import static org.hyades.proto.notification.v1.Scope.SCOPE_PORTFOLIO;
import static org.hyades.proto.notification.v1.Scope.SCOPE_SYSTEM;
import static org.hyades.proto.vuln.v1.Source.SOURCE_INTERNAL;
import static org.hyades.proto.vuln.v1.Source.SOURCE_NVD;
import static org.hyades.proto.vuln.v1.Source.SOURCE_OSSINDEX;
import static org.hyades.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_SUCCESSFUL;
import static org.hyades.proto.vulnanalysis.v1.Scanner.SCANNER_INTERNAL;

public class VulnerabilityScanResultProcessorTest extends PersistenceCapableTest {

    private TopologyTestDriver testDriver;
    private TestInputTopic<UUID, ScanResult> inputTopic;
    private TestOutputTopic<UUID, ScanResult> outputTopic;

    @Before
    public void setUp() {
        final var streamsBuilder = new StreamsBuilder();
        streamsBuilder
                .stream("input-topic", Consumed
                        .with(Serdes.UUID(), new KafkaProtobufSerde<>(ScanResult.parser())))
                .processValues(VulnerabilityScanResultProcessor::new)
                .to("output-topic", Produced
                        .with(Serdes.UUID(), new KafkaProtobufSerde<>(ScanResult.parser())));

        testDriver = new TopologyTestDriver(streamsBuilder.build());
        inputTopic = testDriver.createInputTopic("input-topic",
                new UUIDSerializer(), new KafkaProtobufSerializer<>());
        outputTopic = testDriver.createOutputTopic("output-topic",
                new UUIDDeserializer(), new KafkaProtobufDeserializer<>(ScanResult.parser()));
    }

    @After
    public void tearDown() {
        if (testDriver != null) {
            testDriver.close();
        }
    }

    @Test
    public void forwardCompletionEventTest() {
        final var componentUuid = UUID.randomUUID();
        final var scanToken = UUID.randomUUID().toString();
        final var scanKey = ScanKey.newBuilder().setScanToken(scanToken).setComponentUuid(componentUuid.toString()).build();
        final var scanResult = ScanResult.newBuilder()
                .setKey(scanKey)
                .setScanner(Scanner.SCANNER_NONE)
                .setStatus(ScanStatus.SCAN_STATUS_COMPLETE)
                .build();

        inputTopic.pipeInput(componentUuid, scanResult);

        assertThat(outputTopic.readRecordsToList()).satisfiesExactly(
                record -> {
                    assertThat(record.key()).isEqualTo(componentUuid);
                    assertThat(record.value()).isEqualTo(scanResult);
                }
        );

        assertThat(kafkaMockProducer.history()).isEmpty();
    }

    @Test
    public void dropFailedScanResultTest() {
        final var componentUuid = UUID.randomUUID();
        final var scanToken = UUID.randomUUID().toString();
        final var scanKey = ScanKey.newBuilder().setScanToken(scanToken).setComponentUuid(componentUuid.toString()).build();
        final var scanResult = ScanResult.newBuilder()
                .setKey(scanKey)
                .setScanner(SCANNER_INTERNAL)
                .setStatus(ScanStatus.SCAN_STATUS_FAILED)
                .setFailureReason("just because")
                .build();

        inputTopic.pipeInput(componentUuid, scanResult);

        assertThat(outputTopic.getQueueSize()).isZero();

        assertThat(kafkaMockProducer.history()).satisfiesExactly(
                record -> {
                    assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_ANALYZER.name());
                    final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_ANALYZER, record);
                    assertThat(notification.getScope()).isEqualTo(SCOPE_SYSTEM);
                    assertThat(notification.getLevel()).isEqualTo(LEVEL_ERROR);
                    assertThat(notification.getGroup()).isEqualTo(GROUP_ANALYZER);
                    assertThat(notification.getTitle()).isEqualTo(NotificationConstants.Title.ANALYZER_ERROR);
                    assertThat(notification.getContent()).isEqualTo(
                            "Scan of component %s with %s failed (scanKey: %s): just because",
                            componentUuid, SCANNER_INTERNAL, scanToken + "/" + componentUuid);
                }
        );
    }

    @Test
    public void dropPendingScanResultTest() {
        final var componentUuid = UUID.randomUUID();
        final var scanToken = UUID.randomUUID().toString();
        final var scanKey = ScanKey.newBuilder().setScanToken(scanToken).setComponentUuid(componentUuid.toString()).build();
        final var scanResult = ScanResult.newBuilder()
                .setKey(scanKey)
                .setScanner(SCANNER_INTERNAL)
                .setStatus(ScanStatus.SCAN_STATUS_PENDING)
                .build();

        inputTopic.pipeInput(componentUuid, scanResult);

        assertThat(outputTopic.getQueueSize()).isZero();

        assertThat(kafkaMockProducer.history()).isEmpty();
    }

    @Test
    public void processSuccessfulScanResultWhenComponentDoesNotExistTest() {
        final var componentUuid = UUID.randomUUID();
        final var scanToken = UUID.randomUUID().toString();
        final var scanKey = ScanKey.newBuilder().setScanToken(scanToken).setComponentUuid(componentUuid.toString()).build();
        final var vuln = new Vulnerability();
        vuln.setVulnId("INT-001");
        vuln.setSource(Vulnerability.Source.INTERNAL);
        final var scanResult = ScanResult.newBuilder()
                .setKey(scanKey)
                .setScanner(SCANNER_INTERNAL)
                .setStatus(SCAN_STATUS_SUCCESSFUL)
                .addVulnerabilities(org.hyades.proto.vuln.v1.Vulnerability.newBuilder()
                        .setId("INT-001")
                        .setSource(SOURCE_INTERNAL))
                .build();

        inputTopic.pipeInput(componentUuid, scanResult);

        assertThat(outputTopic.getQueueSize()).isZero();

        assertThat(kafkaMockProducer.history()).isEmpty();
    }

    @Test
    @SuppressWarnings("unchecked")
    public void processSuccessfulScanResult() {
        final var project = new Project();
        project.setName("acme-app");
        project.setVersion("1.0.0");
        qm.persist(project);

        final var component = new Component();
        component.setName("acme-lib");
        component.setVersion("1.1.0");
        component.setProject(project);
        qm.persist(component);

        final var componentUuid = component.getUuid();
        final var scanToken = UUID.randomUUID().toString();
        final var scanKey = ScanKey.newBuilder().setScanToken(scanToken).setComponentUuid(componentUuid.toString()).build();
        final var vulnA = new Vulnerability();
        vulnA.setVulnId("INT-001");
        vulnA.setSource(Vulnerability.Source.INTERNAL);
        qm.persist(vulnA);
        final var vulnB = new Vulnerability();
        vulnB.setVulnId("SONATYPE-002");
        vulnB.setSource(Vulnerability.Source.OSSINDEX);
        final var vulnC = new Vulnerability();
        vulnC.setVulnId("INT-002");
        vulnC.setSource(Vulnerability.Source.INTERNAL);
        final var scanResult = ScanResult.newBuilder()
                .setKey(scanKey)
                .setScanner(SCANNER_INTERNAL)
                .setStatus(SCAN_STATUS_SUCCESSFUL)
                .addVulnerabilities(org.hyades.proto.vuln.v1.Vulnerability.newBuilder()
                        .setId(vulnA.getVulnId())
                        .setSource(SOURCE_INTERNAL))
                .addVulnerabilities(org.hyades.proto.vuln.v1.Vulnerability.newBuilder()
                        .setId(vulnB.getVulnId())
                        .setSource(SOURCE_OSSINDEX))
                .addVulnerabilities(org.hyades.proto.vuln.v1.Vulnerability.newBuilder()
                        .setId(vulnC.getVulnId())
                        .setSource(SOURCE_INTERNAL))
                .build();
        final Headers headers = new RecordHeaders();
        headers.add(KafkaEventHeaders.VULN_ANALYSIS_LEVEL, VulnerabilityAnalysisLevel.BOM_UPLOAD_ANALYSIS.name().getBytes());

        inputTopic.pipeInput(new TestRecord<>(componentUuid, scanResult, headers));

        assertThat(outputTopic.getQueueSize()).isZero();

        qm.getPersistenceManager().refresh(component);
        assertThat(component.getVulnerabilities()).satisfiesExactlyInAnyOrder(
                vuln -> {
                    assertThat(vuln.getVulnId()).isEqualTo("INT-001");
                    assertThat(vuln.getSource()).isEqualTo(Vulnerability.Source.INTERNAL.name());
                },
                vuln -> {
                    assertThat(vuln.getVulnId()).isEqualTo("SONATYPE-002");
                    assertThat(vuln.getSource()).isEqualTo(Vulnerability.Source.OSSINDEX.name());
                }
                // INT-002 is discarded because it is internal but doesn't exist in the database.
        );

        final List<Finding> findings = qm.getFindings(project, false);
        assertThat(findings).satisfiesExactlyInAnyOrder(
                finding -> {
                    assertThat(finding.getVulnerability().get("vulnId")).isEqualTo("INT-001");
                    assertThat(finding.getAttribution().get("analyzerIdentity")).isEqualTo(AnalyzerIdentity.INTERNAL_ANALYZER.name());
                },
                finding -> {
                    assertThat(finding.getVulnerability().get("vulnId")).isEqualTo("SONATYPE-002");
                    assertThat(finding.getAttribution().get("analyzerIdentity")).isEqualTo(AnalyzerIdentity.INTERNAL_ANALYZER.name());
                }
                // INT-002 is discarded because it is internal but doesn't exist in the database.
        );

        assertThat(kafkaMockProducer.history()).satisfiesExactly(
                record -> {
                    assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_NEW_VULNERABILITY.name());
                    final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_NEW_VULNERABILITY, record);
                    assertThat(notification.getScope()).isEqualTo(SCOPE_PORTFOLIO);
                    assertThat(notification.getLevel()).isEqualTo(LEVEL_INFORMATIONAL);
                    assertThat(notification.getGroup()).isEqualTo(GROUP_NEW_VULNERABILITY);
                    assertThat(notification.getSubject().is(NewVulnerabilitySubject.class)).isTrue();
                    final var subject = notification.getSubject().unpack(NewVulnerabilitySubject.class);
                    assertThat(subject.getVulnerabilityAnalysisLevel()).isEqualTo("BOM_UPLOAD_ANALYSIS");
                },
                record -> {
                    assertThat(record.topic()).isEqualTo(KafkaTopics.NOTIFICATION_NEW_VULNERABILITY.name());
                    final Notification notification = deserializeValue(KafkaTopics.NOTIFICATION_NEW_VULNERABILITY, record);
                    assertThat(notification.getScope()).isEqualTo(SCOPE_PORTFOLIO);
                    assertThat(notification.getLevel()).isEqualTo(LEVEL_INFORMATIONAL);
                    assertThat(notification.getGroup()).isEqualTo(GROUP_NEW_VULNERABILITY);
                    assertThat(notification.getSubject().is(NewVulnerabilitySubject.class)).isTrue();
                    final var subject = notification.getSubject().unpack(NewVulnerabilitySubject.class);
                    assertThat(subject.getVulnerabilityAnalysisLevel()).isEqualTo("BOM_UPLOAD_ANALYSIS");
                }
                // INT-002 is discarded because it is internal but doesn't exist in the database.
        );
    }

    @Test
    public void processSuccessfulScanResultWithExistingFindingTest() {
        final var project = new Project();
        project.setName("acme-app");
        project.setVersion("1.0.0");
        qm.persist(project);

        final var component = new Component();
        component.setName("acme-lib");
        component.setVersion("1.1.0");
        component.setProject(project);
        qm.persist(component);

        final var vulnerability = new Vulnerability();
        vulnerability.setVulnId("CVE-001");
        vulnerability.setSource(Vulnerability.Source.NVD);
        qm.persist(vulnerability);
        qm.addVulnerability(vulnerability, component, AnalyzerIdentity.OSSINDEX_ANALYZER);

        final var scanToken = UUID.randomUUID().toString();
        final var scanKey = ScanKey.newBuilder().setScanToken(scanToken).setComponentUuid(component.getUuid().toString()).build();
        final var scanResult = ScanResult.newBuilder()
                .setKey(scanKey)
                .setScanner(SCANNER_INTERNAL)
                .setStatus(SCAN_STATUS_SUCCESSFUL)
                .addVulnerabilities(org.hyades.proto.vuln.v1.Vulnerability.newBuilder()
                        .setId("CVE-001")
                        .setSource(SOURCE_NVD))
                .build();

        inputTopic.pipeInput(component.getUuid(), scanResult);

        qm.getPersistenceManager().refreshAll(component, vulnerability);
        assertThat(component.getVulnerabilities()).satisfiesExactly(
                vuln -> {
                    assertThat(vuln.getVulnId()).isEqualTo("CVE-001");
                    assertThat(vuln.getSource()).isEqualTo(Vulnerability.Source.NVD.name());
                }
        );

        // Attribution should still refer to the first scanner that identified the vulnerability.
        final FindingAttribution attribution = qm.getFindingAttribution(vulnerability, component);
        assertThat(attribution).isNotNull();
        assertThat(attribution.getAnalyzerIdentity()).isEqualTo(AnalyzerIdentity.OSSINDEX_ANALYZER);

        // Because the vulnerability was reported already, no notification must be sent.
        assertThat(kafkaMockProducer.history()).isEmpty();
    }

}