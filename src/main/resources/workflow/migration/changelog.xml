<?xml version="1.1" encoding="UTF-8" standalone="no"?>
<databaseChangeLog
        xmlns="http://www.liquibase.org/xml/ns/dbchangelog"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog
            http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-latest.xsd">
    <changeSet id="1" author="nscuro">
        <sql>
            create type workflow_run_status as enum (
              'PENDING'
            , 'RUNNING'
            , 'SUSPENDED'
            , 'CANCELLED'
            , 'COMPLETED'
            , 'FAILED'
            );

            <!--
              We could partition this table by status, such that completed runs are kept
              separate from non-completed ones. This would speed up polling as the history grows.

                create table workflow_run_terminal partition of workflow_run for values in ('CANCELLED', 'COMPLETED', 'FAILED');
                create table workflow_run_nonterminal partition of workflow_run for values in ('PENDING', 'RUNNING', 'SUSPENDED');

              Some drawbacks though:
                * Queries across partitions (i.e. listing all runs ordered by updated_at) will be more expensive.
                * Uniqueness of IDs can't be enforced across partitions. Should be fine though since we use UUIDv7.
                * We can't have FKs to the workflow_run table anymore, since its PK would need to contain the partition key (status), which is impractical.
            -->
            create table workflow_run (
              id uuid
            , parent_id uuid
            , workflow_name text not null
            , workflow_version smallint not null
            , status workflow_run_status not null default 'PENDING'
            , custom_status text
            , concurrency_group_id text
            , priority smallint
            , tags text[]
            , locked_by text
            , locked_until timestamptz(3)
            , created_at timestamptz(3) not null default now()
            , updated_at timestamptz(3)
            , started_at timestamptz(3)
            , completed_at timestamptz(3)
            , constraint workflow_run_pk primary key (id)
            , constraint workflow_run_parent_fk foreign key (parent_id) references workflow_run (id) on delete cascade
            );

            <!--
              For workflow runs with concurrency group, maintain a sequence for the next run.
              This adds additional overhead to creation and completion of workflow runs,
              but performs magnitudes better than using a PARTITION BY window function
              in the poll query.

              https://docs.hatchet.run/blog/multi-tenant-queues#first-attempt-partition-by
              https://blog.sequinstream.com/build-your-own-sqs-or-kafka-with-postgres/
            -->
            create table workflow_concurrency_group (
              id text
            , next_run_id uuid not null
            , constraint workflow_concurrency_group_pk primary key (id)
            );

            <!--
              NB: This table could be partitioned by workflow_run_id since it's never queried without that ID.
              It's mostly append-only and doesn't accumulate lots of bloat, unless records are deleted (i.e. as part of workflow run retention).
            -->
            create table workflow_run_journal (
              workflow_run_id uuid
            , sequence_number int
            , event bytea not null
            , constraint workflow_run_journal_pk primary key (workflow_run_id, sequence_number)
            , constraint workflow_run_journal_workflow_run_fk foreign key (workflow_run_id) references workflow_run (id) on delete cascade
            );

            <!--
              NB: This table could be partitioned by workflow_run_id since it's never queried without that ID.
              It will usually hold ~1 record per active workflow run and thus will not get that huge.
              But since records are deleted frequently, it might accumulate quite a bit of bloat.
              Partitioning might help with that, but this remains to be verified.
            -->
            create table workflow_run_inbox (
              id bigint generated always as identity
            , workflow_run_id uuid not null
            , visible_from timestamptz(3)
            , locked_by text
            , dequeue_count smallint
            , event bytea not null
            , constraint workflow_run_inbox_pk primary key (id)
            , constraint workflow_run_inbox_workflow_run_fk foreign key (workflow_run_id) references workflow_run (id) on delete cascade
            );

            create table workflow_activity_task (
              workflow_run_id uuid
            , scheduled_event_id int
            , activity_name text not null
            , priority smallint
            , argument bytea
            , visible_from timestamptz(3)
            , locked_by text
            , locked_until timestamptz(3)
            , created_at timestamptz(3) not null default now()
            , updated_at timestamptz(3)
            , constraint workflow_activity_task_pk primary key (workflow_run_id, scheduled_event_id)
            , constraint workflow_activity_task_workflow_run_fk foreign key (workflow_run_id) references workflow_run (id) on delete cascade
            );

            <!--
              NB: A covering index (enabling index-only scans) doesn't yield any benefit here.
              Since the table has such a high churn, the query planner ends up having to check
              the visibility map all the time.
              https://www.pgmustard.com/blog/2019/03/04/index-only-scans-in-postgres
            -->
            create index workflow_run_poll_idx
                on workflow_run (
                      priority desc nulls last
                    , created_at
                    , workflow_name
                    , locked_until)
              where status = any('{PENDING, RUNNING, SUSPENDED}'::workflow_run_status[]);

            create index workflow_run_tags_idx
                on workflow_run using gin (tags)
                where tags is not null;

            create index workflow_run_inbox_workflow_run_id_idx
                on workflow_run_inbox (workflow_run_id);

            create index workflow_activity_task_poll_idx
                on workflow_activity_task (
                     priority desc nulls last
                   , created_at
                   , activity_name
                   , locked_until);

            <!--
              TODO: Reduce fillfactor?
              https://www.cybertec-postgresql.com/en/what-is-fillfactor-and-how-does-it-affect-postgresql-performance/
            -->
            alter table workflow_run set (autovacuum_vacuum_scale_factor = 0.02);
            alter table workflow_concurrency_group set (autovacuum_vacuum_scale_factor = 0.02);
            alter table workflow_run_inbox set (autovacuum_vacuum_scale_factor = 0.02);
            alter table workflow_activity_task set (autovacuum_vacuum_scale_factor = 0.02);
        </sql>
    </changeSet>
</databaseChangeLog>