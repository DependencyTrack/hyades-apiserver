package org.dependencytrack.event.kafka.processor;

import alpine.common.logging.Logger;
import alpine.common.metrics.Metrics;
import alpine.notification.Notification;
import alpine.notification.NotificationLevel;
import com.google.protobuf.Any;
import com.google.protobuf.Timestamp;
import com.google.protobuf.util.Timestamps;
import io.micrometer.core.instrument.Timer;
import org.apache.kafka.streams.processor.api.ContextualFixedKeyProcessor;
import org.apache.kafka.streams.processor.api.ContextualProcessor;
import org.apache.kafka.streams.processor.api.FixedKeyRecord;
import org.dependencytrack.event.kafka.KafkaEventDispatcher;
import org.dependencytrack.event.kafka.KafkaEventHeaders;
import org.dependencytrack.event.kafka.KafkaUtil;
import org.dependencytrack.model.AnalyzerIdentity;
import org.dependencytrack.model.Vulnerability;
import org.dependencytrack.model.VulnerabilityAlias;
import org.dependencytrack.model.VulnerabilityAnalysisLevel;
import org.dependencytrack.model.mapping.PolicyProtoMapper;
import org.dependencytrack.notification.NotificationConstants;
import org.dependencytrack.notification.NotificationGroup;
import org.dependencytrack.notification.NotificationScope;
import org.dependencytrack.notification.persistence.NotificationSubjectDao;
import org.dependencytrack.parser.dependencytrack.ModelConverterCdxToVuln;
import org.dependencytrack.persistence.QueryManager;
import org.dependencytrack.persistence.jdbi.UuidArgumentFactory;
import org.dependencytrack.policy.vulnerability.CelVulnerabilityPolicyEvaluator;
import org.dependencytrack.policy.vulnerability.VulnerabilityPolicy;
import org.dependencytrack.policy.vulnerability.VulnerabilityPolicyEvaluator;
import org.dependencytrack.proto.notification.v1.Group;
import org.dependencytrack.proto.notification.v1.Level;
import org.dependencytrack.proto.notification.v1.Scope;
import org.dependencytrack.proto.policy.v1.Project;
import org.dependencytrack.proto.vulnanalysis.v1.ScanKey;
import org.dependencytrack.proto.vulnanalysis.v1.ScanResult;
import org.dependencytrack.proto.vulnanalysis.v1.ScanStatus;
import org.dependencytrack.proto.vulnanalysis.v1.Scanner;
import org.dependencytrack.proto.vulnanalysis.v1.ScannerResult;
import org.dependencytrack.util.PersistenceUtil;
import org.dependencytrack.util.PersistenceUtil.Differ;
import org.jdbi.v3.core.mapper.reflect.ColumnName;
import org.jdbi.v3.sqlobject.config.RegisterArgumentFactory;
import org.jdbi.v3.sqlobject.config.RegisterBeanMapper;
import org.jdbi.v3.sqlobject.config.RegisterConstructorMapper;
import org.jdbi.v3.sqlobject.customizer.Bind;
import org.jdbi.v3.sqlobject.customizer.BindBean;
import org.jdbi.v3.sqlobject.customizer.BindMethods;
import org.jdbi.v3.sqlobject.statement.GetGeneratedKeys;
import org.jdbi.v3.sqlobject.statement.SqlBatch;
import org.jdbi.v3.sqlobject.statement.SqlQuery;

import javax.jdo.Query;
import javax.ws.rs.core.MultivaluedHashMap;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Objects;
import java.util.Optional;
import java.util.Set;
import java.util.UUID;
import java.util.function.Function;
import java.util.stream.Collectors;

import static org.datanucleus.PropertyNames.PROPERTY_PERSISTENCE_BY_REACHABILITY_AT_COMMIT;
import static org.datanucleus.PropertyNames.PROPERTY_RETAIN_VALUES;
import static org.dependencytrack.model.mapping.VulnerabilityPolicyMapper.map;
import static org.dependencytrack.parser.dependencytrack.ModelConverterCdxToVuln.convert;
import static org.dependencytrack.persistence.jdbi.JdbiFactory.jdbi;
import static org.dependencytrack.proto.vulnanalysis.v1.ScanStatus.SCAN_STATUS_FAILED;
import static org.dependencytrack.proto.vulnanalysis.v1.Scanner.SCANNER_INTERNAL;
import static org.dependencytrack.util.VulnerabilityUtil.canBeMirrored;
import static org.dependencytrack.util.VulnerabilityUtil.isAuthoritativeSource;
import static org.dependencytrack.util.VulnerabilityUtil.isMirroringEnabled;

/**
 * A {@link ContextualProcessor} responsible for processing {@link ScanResult}s.
 */
public class VulnerabilityScanResultProcessor extends ContextualFixedKeyProcessor<ScanKey, ScanResult, ScanResult> {

    private static final Logger LOGGER = Logger.getLogger(VulnerabilityScanResultProcessor.class);
    private static final Timer TIMER = Timer.builder("vuln_scan_result_processing")
            .description("Time taken to process vulnerability scan results")
            .register(Metrics.getRegistry());

    private final KafkaEventDispatcher eventDispatcher = new KafkaEventDispatcher();
    private final VulnerabilityPolicyEvaluator policyEvaluator;

    public VulnerabilityScanResultProcessor() {
        this(new CelVulnerabilityPolicyEvaluator());
    }

    VulnerabilityScanResultProcessor(final VulnerabilityPolicyEvaluator policyEvaluator) {
        this.policyEvaluator = policyEvaluator;
    }

    @Override
    public void process(final FixedKeyRecord<ScanKey, ScanResult> record) {
        final ScanKey scanKey = record.key();
        final ScanResult result = record.value();
        final UUID componentUuid = UUID.fromString(scanKey.getComponentUuid());
        final VulnerabilityAnalysisLevel analysisLevel = determineAnalysisLevel(record);
        final boolean isNewComponent = determineIsComponentNew(record);
        final Timer.Sample timerSample = Timer.start();
        try (final var qm = new QueryManager()) {
            qm.getPersistenceManager().setProperty(PROPERTY_PERSISTENCE_BY_REACHABILITY_AT_COMMIT, "false");
            // Do not unload fields upon transaction commit.
            //   https://www.datanucleus.org/products/accessplatform_6_0/jdo/persistence.html#lifecycle
            qm.getPersistenceManager().setProperty(PROPERTY_RETAIN_VALUES, "true");

            final Optional<Component> optionalComponent = jdbi(qm).withExtension(Dao.class, dao -> dao.getComponentByUuid(componentUuid));
            if (optionalComponent.isEmpty()) {
                LOGGER.warn("Received result for component %s, but it does not exist (scanKey: %s)"
                        .formatted(componentUuid, prettyPrint(scanKey)));
                return;
            }

            for (final ScannerResult scannerResult : result.getScannerResultsList()) {
                processScannerResult(qm, optionalComponent.get(), scanKey, scannerResult, analysisLevel, isNewComponent);
            }
        } catch (Exception e) {
            LOGGER.error("Failed to process scan result for component %s (scanKey: %s)"
                    .formatted(componentUuid, prettyPrint(scanKey)), e);
        } finally {
            timerSample.stop(TIMER);
            context().forward(record);
        }
    }

    private void processScannerResult(final QueryManager qm, final Component component,
                                      final ScanKey scanKey, final ScannerResult scannerResult,
                                      final VulnerabilityAnalysisLevel analysisLevel,
                                      final boolean isNewComponent) {
        if (scannerResult.getStatus() == SCAN_STATUS_FAILED) {
            final var message = "Scan of component %s with %s failed (scanKey: %s): %s"
                    .formatted(component.uuid(), scannerResult.getScanner(), prettyPrint(scanKey), scannerResult.getFailureReason());
            eventDispatcher.dispatchAsync(UUID.fromString(component.projectUuid()), new Notification()
                    .scope(NotificationScope.SYSTEM)
                    .group(NotificationGroup.ANALYZER)
                    .level(NotificationLevel.ERROR)
                    .title(NotificationConstants.Title.ANALYZER_ERROR)
                    .content(message));
            LOGGER.warn(message);
            return;
        } else if (scannerResult.getStatus() != ScanStatus.SCAN_STATUS_SUCCESSFUL) {
            LOGGER.warn("Unable to process results from %s with status %s; Dropping record (scanKey: %s)"
                    .formatted(scannerResult.getScanner(), scannerResult.getStatus(), prettyPrint(scanKey)));
            return;
        }

        final Set<Vulnerability> syncedVulns = syncVulnerabilities(qm, scanKey, scannerResult);
        LOGGER.debug("Synchronized %d vulnerabilities reported by %s for %s (scanKey: %s)"
                .formatted(syncedVulns.size(), scannerResult.getScanner(), scanKey.getComponentUuid(), prettyPrint(scanKey)));

        final Set<Vulnerability> newVulns = addVulnerabilities(qm, component, syncedVulns, scannerResult.getScanner());
        LOGGER.debug("Identified %d new vulnerabilities for %s with %s (scanKey: %s)"
                .formatted(newVulns.size(), scanKey.getComponentUuid(), scannerResult.getScanner(), prettyPrint(scanKey)));

        final Timestamp notificationTimestamp = Timestamps.now();
        final var notifications = new ArrayList<org.dependencytrack.proto.notification.v1.Notification>();

        jdbi(qm).useExtension(NotificationSubjectDao.class, notificationSubjectDao -> {
            if (isNewComponent && !syncedVulns.isEmpty()) {
                notificationSubjectDao.getForNewVulnerableDependency(component.uuid())
                        .map(subject -> org.dependencytrack.proto.notification.v1.Notification.newBuilder()
                                .setScope(Scope.SCOPE_PORTFOLIO)
                                .setGroup(Group.GROUP_NEW_VULNERABLE_DEPENDENCY)
                                .setLevel(Level.LEVEL_INFORMATIONAL)
                                .setTimestamp(notificationTimestamp)
                                .setTitle("")
                                .setContent("")
                                .setSubject(Any.pack(subject))
                                .build())
                        .ifPresent(notifications::add);
            }
            if (!newVulns.isEmpty()) {
                notificationSubjectDao.getForNewVulnerabilities(component.uuid(), newVulns.stream().map(Vulnerability::getUuid).map(UUID::toString).toList()).stream()
                        .map(subject -> org.dependencytrack.proto.notification.v1.Notification.newBuilder()
                                .setScope(Scope.SCOPE_PORTFOLIO)
                                .setGroup(Group.GROUP_NEW_VULNERABILITY)
                                .setLevel(Level.LEVEL_INFORMATIONAL)
                                .setTimestamp(notificationTimestamp)
                                .setTitle("")
                                .setContent("")
                                .setSubject(Any.pack(subject))
                                .build())
                        .forEach(notifications::add);
            }
        });
    }

    /**
     * Synchronize vulnerabilities reported in a given {@link ScannerResult} with the datastore.
     *
     * @param qm            The {@link QueryManager} to use
     * @param scanKey       The {@link ScanKey} associated with the {@link ScannerResult}
     * @param scannerResult The {@link ScannerResult} to synchronize vulnerabilities from
     * @return A {@link Set} of synchronized {@link Vulnerability}s
     */
    private Set<Vulnerability> syncVulnerabilities(final QueryManager qm, final ScanKey scanKey, final ScannerResult scannerResult) {
        final var syncedVulns = new HashSet<Vulnerability>();

        for (final org.cyclonedx.proto.v1_4.Vulnerability reportedVuln : scannerResult.getBom().getVulnerabilitiesList()) {
            final Vulnerability vuln;
            try {
                vuln = ModelConverterCdxToVuln.convert(qm, scannerResult.getBom(), reportedVuln, true);
            } catch (RuntimeException e) {
                LOGGER.error("Failed to convert vulnerability %s/%s (reported by %s for component %s) to internal model (scanKey: %s)"
                        .formatted(reportedVuln.getSource(), reportedVuln.getId(), scannerResult.getScanner(), scanKey.getComponentUuid(), prettyPrint(scanKey)), e);
                continue;
            }

            try {
                syncedVulns.add(syncVulnerability(qm, vuln, scannerResult.getScanner()));
                if (vuln.getAliases() != null && !vuln.getAliases().isEmpty()) {
                    for (VulnerabilityAlias alias : vuln.getAliases()) {
                        qm.synchronizeVulnerabilityAlias(alias);
                    }
                }
            } catch (RuntimeException e) {
                // Use a broad catch here, so we can still try to process other
                // vulnerabilities, even though processing one of them failed.

                LOGGER.warn("Failed to synchronize vulnerability %s/%s (reported by %s for component %s; scanKey: %s)"
                        .formatted(vuln.getSource(), vuln.getVulnId(), scannerResult.getScanner(), scanKey.getComponentUuid(), prettyPrint(scanKey)), e);
            }
        }

        return syncedVulns;
    }

    /**
     * Synchronize a given {@link Vulnerability} as reported by a given {@link Scanner} with the datastore.
     * <p>
     * This method differs from {@link QueryManager#synchronizeVulnerability(Vulnerability, boolean)} in that it expects
     * an active {@link javax.jdo.Transaction}, and only calls setters of existing vulnerabilities when the respective
     * value actually changed, saving network round-trips.
     *
     * @param qm      The {@link QueryManager} to use
     * @param vuln    The {@link Vulnerability} to synchronize
     * @param scanner The {@link AnalyzerIdentity} that reported the vulnerability
     * @return The synchronized {@link Vulnerability}
     * @throws IllegalStateException  When no {@link javax.jdo.Transaction} is active
     * @throws NoSuchElementException When the reported vulnerability is internal, but does not exist in the datastore
     */
    private Vulnerability syncVulnerability(final QueryManager qm, final Vulnerability vuln, final Scanner scanner) {
        // It is possible that the same vulnerability is reported for multiple components in parallel,
        // causing unique constraint violations when attempting to INSERT into the VULNERABILITY table.
        // In such cases, we can get away with simply retrying to SELECT or INSERT again.
        return qm.runInRetryableTransaction(() -> {
            final Vulnerability existingVuln;
            final Query<Vulnerability> query = qm.getPersistenceManager().newQuery(Vulnerability.class);
            try {
                query.setFilter("vulnId == :vulnId && source == :source");
                query.setParameters(vuln.getVulnId(), vuln.getSource());
                existingVuln = query.executeUnique();
            } finally {
                query.closeAll();
            }

            if (existingVuln == null) {
                if (Vulnerability.Source.INTERNAL.name().equals(vuln.getSource())) {
                    throw new NoSuchElementException("An internal vulnerability with ID %s does not exist".formatted(vuln.getVulnId()));
                }

                return qm.getPersistenceManager().makePersistent(vuln);
            }

            if (canUpdateVulnerability(existingVuln, scanner)) {
                final var differ = new Differ<>(existingVuln, vuln);

                // TODO: Consider using something like javers to get a rich diff of WHAT changed; https://github.com/javers/javers
                differ.applyIfChanged("title", Vulnerability::getTitle, existingVuln::setTitle);
                differ.applyIfChanged("subTitle", Vulnerability::getSubTitle, existingVuln::setSubTitle);
                differ.applyIfChanged("description", Vulnerability::getDescription, existingVuln::setDescription);
                differ.applyIfChanged("detail", Vulnerability::getDetail, existingVuln::setDetail);
                differ.applyIfChanged("recommendation", Vulnerability::getRecommendation, existingVuln::setRecommendation);
                differ.applyIfChanged("references", Vulnerability::getReferences, existingVuln::setReferences);
                differ.applyIfChanged("credits", Vulnerability::getCredits, existingVuln::setCredits);
                differ.applyIfChanged("created", Vulnerability::getCreated, existingVuln::setCreated);
                differ.applyIfChanged("published", Vulnerability::getPublished, existingVuln::setPublished);
                differ.applyIfChanged("updated", Vulnerability::getUpdated, existingVuln::setUpdated);
                differ.applyIfChanged("cwes", Vulnerability::getCwes, existingVuln::setCwes);
                // Calling setSeverity nulls all CVSS and OWASP RR fields. getSeverity calculates the severity on-the-fly,
                // and will return UNASSIGNED even when no severity is set explicitly. Thus, calling setSeverity
                // must happen before CVSS and OWASP RR fields are set, to avoid null-ing them again.
                differ.applyIfChanged("severity", Vulnerability::getSeverity, existingVuln::setSeverity);
                differ.applyIfChanged("cvssV2BaseScore", Vulnerability::getCvssV2BaseScore, existingVuln::setCvssV2BaseScore);
                differ.applyIfChanged("cvssV2ImpactSubScore", Vulnerability::getCvssV2ImpactSubScore, existingVuln::setCvssV2ImpactSubScore);
                differ.applyIfChanged("cvssV2ExploitabilitySubScore", Vulnerability::getCvssV2ExploitabilitySubScore, existingVuln::setCvssV2ExploitabilitySubScore);
                differ.applyIfChanged("cvssV2Vector", Vulnerability::getCvssV2Vector, existingVuln::setCvssV2Vector);
                differ.applyIfChanged("cvssv3BaseScore", Vulnerability::getCvssV3BaseScore, existingVuln::setCvssV3BaseScore);
                differ.applyIfChanged("cvssV3ImpactSubScore", Vulnerability::getCvssV3ImpactSubScore, existingVuln::setCvssV3ImpactSubScore);
                differ.applyIfChanged("cvssV3ExploitabilitySubScore", Vulnerability::getCvssV3ExploitabilitySubScore, existingVuln::setCvssV3ExploitabilitySubScore);
                differ.applyIfChanged("cvssV3Vector", Vulnerability::getCvssV3Vector, existingVuln::setCvssV3Vector);
                differ.applyIfChanged("owaspRRLikelihoodScore", Vulnerability::getOwaspRRLikelihoodScore, existingVuln::setOwaspRRLikelihoodScore);
                differ.applyIfChanged("owaspRRTechnicalImpactScore", Vulnerability::getOwaspRRTechnicalImpactScore, existingVuln::setOwaspRRTechnicalImpactScore);
                differ.applyIfChanged("owaspRRBusinessImpactScore", Vulnerability::getOwaspRRBusinessImpactScore, existingVuln::setOwaspRRBusinessImpactScore);
                differ.applyIfChanged("owaspRRVector", Vulnerability::getOwaspRRVector, existingVuln::setOwaspRRVector);
                // Aliases of existingVuln will always be null, as they'd have to be fetched separately.
                // Synchronization of aliases is performed after synchronizing the vulnerability.
                // updated |= applyIfChanged(existingVuln, vuln, Vulnerability::getAliases, existingVuln::setAliases);

                differ.applyIfChanged("vulnerableVersions", Vulnerability::getVulnerableVersions, existingVuln::setVulnerableVersions);
                differ.applyIfChanged("patchedVersions", Vulnerability::getPatchedVersions, existingVuln::setPatchedVersions);
                // EPSS is an additional enrichment that no scanner currently provides.
                // We don't want EPSS scores of CVEs to be purged just because the CVE information came from e.g. OSS Index.
                differ.applyIfNonNullAndChanged("epssScore", Vulnerability::getEpssScore, existingVuln::setEpssScore);
                differ.applyIfNonNullAndChanged("epssPercentile", Vulnerability::getEpssPercentile, existingVuln::setEpssPercentile);

                if (!differ.getDiffs().isEmpty()) {
                    // TODO: Send a notification?
                    //   (But notifications should only be sent if the transaction was committed)
                    // TODO: Reduce to DEBUG; It's set to INFO for testing
                    LOGGER.info("Vulnerability %s/%s was updated by %s: %s".formatted(vuln.getSource(), vuln.getVulnId(), scanner, differ.getDiffs()));
                }
            }

            return existingVuln;
        }, PersistenceUtil::isUniqueConstraintViolation);
    }

    /**
     * Associate a given {@link Set} of {@link Vulnerability}s with a given {@link Component}.
     * <p>
     * If a {@link Vulnerability} was not previously associated with the {@link Component},
     * a {@link FindingAttribution} will be created for the {@link Scanner}.
     *
     * @param qm        The {@link QueryManager} to use
     * @param component The {@link Component} to associate with
     * @param vulns     The {@link Vulnerability}s to associate with
     * @param scanner   The {@link Scanner} that identified the association
     * @return A {@link Set} of {@link Vulnerability}s that were not previously associated with the {@link Component}
     */
    private Set<Vulnerability> addVulnerabilities(final QueryManager qm, final Component component,
                                                  final Set<Vulnerability> vulns, final Scanner scanner) {
        final Map<UUID, VulnerabilityPolicy> matchedPoliciesByVulnUuid;
        if (true) { // TODO: Use feature flag.
            final org.dependencytrack.proto.policy.v1.Project protoProject = Project.newBuilder().setUuid(component.projectUuid()).build();
            final org.dependencytrack.proto.policy.v1.Component protoComponent = org.dependencytrack.proto.policy.v1.Component.newBuilder().setUuid(component.uuid()).build();
            final List<org.dependencytrack.proto.policy.v1.Vulnerability> protoVulns = qm.getPersistenceManager().detachCopyAll(vulns).stream().map(PolicyProtoMapper::mapToProto).toList();
            matchedPoliciesByVulnUuid = policyEvaluator.evaluate(protoVulns, protoComponent, protoProject);
        } else {
            matchedPoliciesByVulnUuid = Collections.emptyMap();
        }

        jdbi(qm).useTransaction(jdbiHandle -> {
            final var dao = jdbiHandle.attach(Dao.class);

            final List<Long> newFindingVulnIds = dao.createFindings(component, vulns);
            final List<FindingAttribution> findingAttributions = newFindingVulnIds.stream()
                    .map(vulnId -> new FindingAttribution(vulnId, component.id(), component.projectId(),
                            convert(scanner).name(), UUID.randomUUID().toString()))
                    .toList();
            dao.createFindingAttributions(findingAttributions);

            if (matchedPoliciesByVulnUuid.isEmpty()) {
                return;
            }

            final Map<String, Analysis> existingAnalyses = dao.getAnalyses(component, matchedPoliciesByVulnUuid.keySet()).stream()
                    .collect(Collectors.toMap(x -> x.vulnUuid, Function.identity()));

            final var analysesToUpsert = new ArrayList<Analysis>();
            final var analysisComments = new MultivaluedHashMap<Long, AnalysisComment>();
            for (final UUID vulnUuid : matchedPoliciesByVulnUuid.keySet()) {
                final VulnerabilityPolicy policy = matchedPoliciesByVulnUuid.get(vulnUuid);
                final Analysis existingAnalysis = existingAnalyses.get(vulnUuid.toString());
                if (existingAnalysis == null) {
                    final var analysis = new Analysis();
                    analysis.setComponentId(component.id());
                    analysis.setProjectId(component.projectId());
                    analysis.setVulnId(vulns.stream().filter(v -> v.getUuid().equals(vulnUuid)).map(Vulnerability::getId).findFirst().orElseThrow());
                    analysis.setVulnUuid(vulnUuid.toString());
                    analysis.setState(Optional.ofNullable(map(policy.analysis().state())).map(Enum::name).orElse(null));
                    if (analysis.state != null) {
                        analysisComments.add(analysis.vulnId, new AnalysisComment(0, "State: NOT_SET → %s".formatted(analysis.state), "Policy"));
                    }
                    analysis.setJustification(Optional.ofNullable(map(policy.analysis().justification())).map(Enum::name).orElse(null));
                    if (analysis.justification != null) {
                        analysisComments.add(analysis.vulnId, new AnalysisComment(0, "Justification: NOT_SET → %s".formatted(analysis.justification), "Policy"));
                    }
                    analysis.setResponse(Optional.ofNullable(map(policy.analysis().response())).map(Enum::name).orElse(null));
                    if (analysis.response != null) {
                        analysisComments.add(analysis.vulnId, new AnalysisComment(0, "Response: NOT_SET → %s".formatted(analysis.response), "Policy"));
                    }
                    analysis.setDetails(policy.analysis().details());
                    if (analysis.details != null) {
                        analysisComments.add(analysis.vulnId, new AnalysisComment(0, "Details: %s".formatted(analysis.details), "Policy"));
                    }
                    analysis.setSuppressed(policy.analysis().suppress());
                    if (analysis.suppressed) {
                        analysisComments.add(analysis.vulnId, new AnalysisComment(0, "Suppressed", "Policy"));
                    }
                    analysesToUpsert.add(analysis);
                } else {
                    boolean shouldUpdate = false;
                    if (policy.analysis().state() != null && !Objects.equals(existingAnalysis.state, map(policy.analysis().state()).name())) {
                        analysisComments.add(existingAnalysis.vulnId, new AnalysisComment(existingAnalysis.id, "State: %s → %s".formatted(existingAnalysis.state, policy.analysis().state()), "Policy"));
                        existingAnalysis.setState(map(policy.analysis().state()).name());
                        shouldUpdate = true;
                    }
                    if (policy.analysis().justification() != null && !Objects.equals(existingAnalysis.justification, map(policy.analysis().justification()).name())) {
                        analysisComments.add(existingAnalysis.vulnId, new AnalysisComment(existingAnalysis.id, "Justification: %s → %s".formatted(existingAnalysis.justification, policy.analysis().justification()), "Policy"));
                        existingAnalysis.setJustification(map(policy.analysis().justification()).name());
                        shouldUpdate = true;
                    }
                    if (policy.analysis().response() != null && !Objects.equals(existingAnalysis.response, map(policy.analysis().response()).name())) {
                        analysisComments.add(existingAnalysis.vulnId, new AnalysisComment(existingAnalysis.id, "Response: %s → %s".formatted(existingAnalysis.response, policy.analysis().response()), "Policy"));
                        existingAnalysis.setResponse(map(policy.analysis().response()).name());
                        shouldUpdate = true;
                    }
                    if (policy.analysis().details() != null && !Objects.equals(existingAnalysis.details, policy.analysis().details())) {
                        analysisComments.add(existingAnalysis.vulnId, new AnalysisComment(existingAnalysis.id, "Details: %s → %s".formatted(existingAnalysis.details, policy.analysis().details()), "Policy"));
                        existingAnalysis.setDetails(policy.analysis().details());
                        shouldUpdate = true;
                    }
                    if (existingAnalysis.suppressed == null || (existingAnalysis.suppressed != policy.analysis().suppress())) {
                        analysisComments.add(existingAnalysis.vulnId, new AnalysisComment(existingAnalysis.id, "Suppressed: %s → %s".formatted(existingAnalysis.suppressed, policy.analysis().suppress()), "Policy"));
                        existingAnalysis.setSuppressed(policy.analysis().suppress());
                        shouldUpdate = true;
                    }
                    if (shouldUpdate) {
                        analysesToUpsert.add(existingAnalysis);
                    }
                }
            }

            if (!analysesToUpsert.isEmpty()) {
                final List<CreatedAnalysis> createdAnalyses = dao.createOrUpdateAnalyses(analysesToUpsert);
                for (final CreatedAnalysis createdAnalysis : createdAnalyses) {
                    analysisComments.computeIfPresent(createdAnalysis.vulnId, (vulnId, comments) -> comments.stream()
                            .map(comment -> new AnalysisComment(createdAnalysis.id, comment.comment(), comment.commenter()))
                            .toList());
                }

                dao.createAnalysisComments(analysisComments.values().stream().flatMap(Collection::stream).toList());
            }
        });

        return Collections.emptySet();
    }

    private boolean canUpdateVulnerability(final Vulnerability vuln, final Scanner scanner) {
        var canUpdate = true;

        // Results from the internal scanner only contain vulnId and source, nothing else.
        // As they only refer to existing vulnerabilities in the database, no update must be performed.
        canUpdate &= scanner != SCANNER_INTERNAL;

        // Internal vulnerabilities can only be updated via REST API.
        canUpdate &= !Vulnerability.Source.INTERNAL.name().equals(vuln.getSource());

        // If the scanner is also the authoritative source of the given vulnerability,
        // it should be able to update it. This will be the case for the OSS Index scanner
        // and sonatype-XXX vulnerabilities for example.
        canUpdate &= isAuthoritativeSource(vuln, convert(scanner))
                // Alternatively, if the vulnerability could be mirrored, but mirroring
                // is disabled, it is OK to override any existing data.
                //
                // Ideally, we'd track the data from all sources instead of just overriding
                // it, but for now this will have to do it.
                || (canBeMirrored(vuln) && !isMirroringEnabled(vuln));

        return canUpdate;
    }

    private static VulnerabilityAnalysisLevel determineAnalysisLevel(final FixedKeyRecord<?, ?> record) {
        return KafkaUtil.getEventHeader(record.headers(), KafkaEventHeaders.VULN_ANALYSIS_LEVEL)
                .map(value -> {
                    try {
                        return VulnerabilityAnalysisLevel.valueOf(value);
                    } catch (IllegalArgumentException e) {
                        LOGGER.warn("The reported analysis type %s is invalid, assuming %s"
                                .formatted(value, VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS));
                        return VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS;
                    }
                })
                .orElse(VulnerabilityAnalysisLevel.PERIODIC_ANALYSIS);
    }

    private static boolean determineIsComponentNew(final FixedKeyRecord<?, ?> record) {
        return KafkaUtil.getEventHeader(record.headers(), KafkaEventHeaders.IS_NEW_COMPONENT)
                .map(Boolean::parseBoolean)
                .orElse(false);
    }

    private static String prettyPrint(final ScanKey scanKey) {
        return "%s/%s".formatted(scanKey.getScanToken(), scanKey.getComponentUuid());
    }

    public interface Dao {

        @SqlQuery("""
                SELECT
                  "C"."ID"   AS "id",
                  "C"."UUID" AS "uuid",
                  "P"."ID"   AS "projectId",
                  "P"."UUID" AS "projectUuid"
                FROM
                  "COMPONENT" AS "C"
                INNER JOIN
                  "PROJECT" AS "P" ON "P"."ID" = "C"."PROJECT_ID"
                WHERE
                  "C"."UUID" = :uuid
                """)
        @RegisterConstructorMapper(Component.class)
        @RegisterArgumentFactory(UuidArgumentFactory.class)
        Optional<Component> getComponentByUuid(@Bind("uuid") final UUID uuid);

        @SqlBatch("""
                INSERT INTO "COMPONENTS_VULNERABILITIES"
                  ("COMPONENT_ID", "VULNERABILITY_ID")
                VALUES
                  (:component.id, :vuln.id)
                ON CONFLICT DO NOTHING
                RETURNING "VULNERABILITY_ID"
                """)
        @GetGeneratedKeys("VULNERABILITY_ID")
        List<Long> createFindings(@BindMethods("component") final Component component, @BindBean("vuln") final Iterable<Vulnerability> vuln);

        @SqlBatch("""
                INSERT INTO "FINDINGATTRIBUTION"
                  ("VULNERABILITY_ID", "COMPONENT_ID", "PROJECT_ID", "ANALYZERIDENTITY", "ATTRIBUTED_ON", "UUID")
                VALUES
                  (:vulnId, :componentId, :projectId, :analyzer, NOW(), :uuid)
                ON CONFLICT ("VULNERABILITY_ID", "COMPONENT_ID") DO NOTHING
                """)
        void createFindingAttributions(@BindMethods final Iterable<FindingAttribution> attribution);

        @SqlQuery("""
                SELECT
                  "V"."ID"            AS "vulnId",
                  "V"."UUID"          AS "vulnUuid",
                  "A"."ID"            AS "id",
                  "A"."COMPONENT_ID"  AS "componentId",
                  "A"."PROJECT_ID"    AS "projectId",
                  "A"."STATE"         AS "state",
                  "A"."JUSTIFICATION" AS "justification",
                  "A"."RESPONSE"      AS "response",
                  "A"."DETAILS"       AS "details",
                  "A"."SUPPRESSED"    AS "suppressed"
                FROM
                  "VULNERABILITY" AS "V"
                INNER JOIN
                  "ANALYSIS" AS "A" ON "A"."VULNERABILITY_ID" = "V"."ID"
                WHERE
                  "A"."COMPONENT_ID" = :component.id
                  AND "V"."UUID" = ANY(:vulnUuids)
                """)
        @RegisterBeanMapper(Analysis.class)
        @RegisterArgumentFactory(UuidArgumentFactory.class)
        List<Analysis> getAnalyses(@BindMethods("component") final Component component, @Bind("vulnUuids") final Iterable<String> vulnUuids);

        default List<Analysis> getAnalyses(final Component component, final Collection<UUID> vulnUuids) {
            return getAnalyses(component, vulnUuids.stream().map(UUID::toString).toList());
        }

        @SqlBatch("""
                INSERT INTO "ANALYSIS"
                  ("VULNERABILITY_ID", "COMPONENT_ID", "PROJECT_ID", "STATE", "JUSTIFICATION", "RESPONSE", "DETAILS", "SUPPRESSED")
                VALUES
                  (:vulnId, :componentId, :projectId, :state, :justification, :response, :details, :suppressed)
                ON CONFLICT ("VULNERABILITY_ID", "COMPONENT_ID", "PROJECT_ID") DO UPDATE
                  SET
                    "STATE" = :state,
                    "JUSTIFICATION" = :justification,
                    "RESPONSE" = :response,
                    "DETAILS" = :details,
                    "SUPPRESSED" = :suppressed
                RETURNING "ID", "VULNERABILITY_ID"
                """)
        @GetGeneratedKeys({"ID", "VULNERABILITY_ID"})
        @RegisterConstructorMapper(CreatedAnalysis.class)
        List<CreatedAnalysis> createOrUpdateAnalyses(@BindBean final Iterable<Analysis> analysis);

        @SqlBatch("""
                INSERT INTO "ANALYSISCOMMENT"
                  ("ANALYSIS_ID", "TIMESTAMP", "COMMENT", "COMMENTER")
                VALUES
                  (:analysisId, NOW(), :comment, :commenter)
                """)
        void createAnalysisComments(@BindMethods final Iterable<AnalysisComment> comment);

    }

    public static class Analysis {

        private long id;
        private long componentId;
        private long projectId;
        private long vulnId;
        private String vulnUuid;
        private String state;
        private String justification;
        private String response;
        private String details;
        private Boolean suppressed;

        public long getId() {
            return id;
        }

        public void setId(final long id) {
            this.id = id;
        }

        public long getComponentId() {
            return componentId;
        }

        public void setComponentId(final long componentId) {
            this.componentId = componentId;
        }

        public long getProjectId() {
            return projectId;
        }

        public void setProjectId(final long projectId) {
            this.projectId = projectId;
        }

        public long getVulnId() {
            return vulnId;
        }

        public void setVulnId(final long vulnId) {
            this.vulnId = vulnId;
        }

        public String getVulnUuid() {
            return vulnUuid;
        }

        public void setVulnUuid(final String vulnUuid) {
            this.vulnUuid = vulnUuid;
        }

        public String getState() {
            return state;
        }

        public void setState(final String state) {
            this.state = state;
        }

        public String getJustification() {
            return justification;
        }

        public void setJustification(final String justification) {
            this.justification = justification;
        }

        public String getResponse() {
            return response;
        }

        public void setResponse(final String response) {
            this.response = response;
        }

        public String getDetails() {
            return details;
        }

        public void setDetails(final String details) {
            this.details = details;
        }

        public Boolean getSuppressed() {
            return suppressed;
        }

        public void setSuppressed(final Boolean suppressed) {
            this.suppressed = suppressed;
        }

    }

    public record CreatedAnalysis(long id, @ColumnName("VULNERABILITY_ID") long vulnId) {
    }

    public record AnalysisComment(long analysisId, String comment, String commenter) {
    }

    public record Component(long id, String uuid, long projectId, String projectUuid) {
    }

    public record FindingAttribution(long vulnId, long componentId, long projectId, String analyzer, String uuid) {
    }

}
